Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Policy/Curiosity Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Policy/Curiosity Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Losses/Curiosity Forward Loss,Losses/Curiosity Inverse Loss,Is Training
10000,2.1632004,62.271186440677965,-0.29332608,0.07247475,1.3263096597235082,1.3263096597235082,0.03988544223040848,0.5645653,0.10122444,9.994619e-05,0.10268783,1.3708674,1.0
20000,1.9843937,21.416666666666668,-0.006364493,0.15182461,3.670985698699951,3.670985698699951,0.03953378575274369,0.6801814,0.09495311,9.9846e-05,0.16897328,0.74696034,1.0
30000,1.8262237,14.86283185840708,0.8464602,0.23828523,4.589299222009372,4.589299222009372,0.0189206055159458,0.9643272,0.0958077,9.974634e-05,0.1548899,0.6973241,1.0
40000,1.6860594,28.04,0.37356225,0.240384,4.440501070939577,4.440501070939577,0.04766145119300255,0.16768408,0.09740053,9.9650315e-05,0.1923616,0.940061,1.0
